{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":476053,"sourceType":"datasetVersion","datasetId":221051}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-01-31T12:17:47.041034Z","iopub.execute_input":"2024-01-31T12:17:47.041722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nfrom random import shuffle\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2024-02-01T13:41:25.569394Z","iopub.execute_input":"2024-02-01T13:41:25.570255Z","iopub.status.idle":"2024-02-01T13:41:25.574761Z","shell.execute_reply.started":"2024-02-01T13:41:25.570225Z","shell.execute_reply":"2024-02-01T13:41:25.573714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def haar_cascade_classifier(image):\n    face_classifier = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n    face = face_classifier.detectMultiScale(image, scaleFactor=1.1, minNeighbors=5, minSize=(40, 40))\n    \n    if len(face) == 0:\n        return None\n    for (x, y, w, h) in face:\n        cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 4)\n    img_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    return img_rgb","metadata":{"execution":{"iopub.status.busy":"2024-02-01T13:41:26.507064Z","iopub.execute_input":"2024-02-01T13:41:26.507617Z","iopub.status.idle":"2024-02-01T13:41:26.514403Z","shell.execute_reply.started":"2024-02-01T13:41:26.507586Z","shell.execute_reply":"2024-02-01T13:41:26.513341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_train_data(TRAIN_DIR, LABEL_DIR):\n    c0=0\n    c1=0\n    res=0\n    \n    training_data = []\n    label_data = []\n    \n    for folder in os.listdir( LABEL_DIR ):\n        c0=0\n        \n        for inner_folder in os.listdir( (LABEL_DIR+'/'+folder) ):\n            path = os.path.join(LABEL_DIR, folder+'/'+inner_folder)\n            \n            for text_file in os.listdir( (path) ):\n                text_file = os.path.join(path+'/'+text_file)\n                with open(text_file) as opened_file:\n                    lines = opened_file.readlines()\n                    if(lines[0][3]=='0' and c0<340):\n                        label_data.append(0)\n                        res+=1\n                        c0+=1\n                    if(lines[0][3]!='0'):\n                        label_data.append(1)\n                        c1+=1\n                    opened_file.close()\n    \n    label_data.append(-1)\n    print(str(res)+ ' '+str(c1))\n    \n    c=0\n    c0=0\n    c1=0\n    res=0\n    print(len(label_data))\n    \n    for folder in os.listdir(TRAIN_DIR):\n        c0=0\n        for inner_folder in os.listdir( (TRAIN_DIR+'/'+folder) ):\n            path = os.path.join(TRAIN_DIR, folder+'/'+inner_folder)\n            for img in tqdm( os.listdir(path) ):\n                img = os.path.join(path+'/'+img)\n                img_data = cv2.imread(img, cv2.IMREAD_COLOR)\n                #img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY)\n\n                # PRE-PROCESSING & FACE DETECTION\n                img_data = haar_cascade_classifier(img_data)\n                if img_data is None:\n                    continue\n                \n                #img_data = cv2.cvtColor(img_data, cv2.COLOR_RGB2BGR)\n                \n                if (label_data[c]==-1):break\n                    \n                # TRAINING_DATA = LISTOF([image_array, Label])\n                if (label_data[c]==0 and c0<340):\n                    training_data.append([np.array(img_data), label_data[c]])\n                    c0+=1\n                    res+=1\n                    c+=1\n                if (label_data[c]!=0):\n                    training_data.append([np.array(img_data), label_data[c]])\n                    c+=1\n                    c1+=1\n                    \n    print(str(res)+' '+str(c1))\n    shuffle(training_data)\n    return training_data","metadata":{"execution":{"iopub.status.busy":"2024-02-01T13:44:09.998276Z","iopub.execute_input":"2024-02-01T13:44:09.999166Z","iopub.status.idle":"2024-02-01T13:44:10.013040Z","shell.execute_reply.started":"2024-02-01T13:44:09.999133Z","shell.execute_reply":"2024-02-01T13:44:10.012098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_DIR = \"/kaggle/input/emotionpain/Images\"\nLABEL_DIR = \"/kaggle/input/emotionpain/Frame_Labels\"\n\n\nfor fol in os.listdir(TRAIN_DIR):\n    path1 = os.path.join(TRAIN_DIR+'/'+fol)\nfor folder in os.listdir(LABEL_DIR):\n    path2 = os.path.join(LABEL_DIR+'/'+folder+'/PSPI')","metadata":{"execution":{"iopub.status.busy":"2024-02-01T13:44:10.444716Z","iopub.execute_input":"2024-02-01T13:44:10.445110Z","iopub.status.idle":"2024-02-01T13:44:10.451491Z","shell.execute_reply.started":"2024-02-01T13:44:10.445077Z","shell.execute_reply":"2024-02-01T13:44:10.450679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_data = create_train_data(path1, path2)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T13:44:13.422143Z","iopub.execute_input":"2024-02-01T13:44:13.422899Z","iopub.status.idle":"2024-02-01T14:15:22.667449Z","shell.execute_reply.started":"2024-02-01T13:44:13.422867Z","shell.execute_reply":"2024-02-01T14:15:22.666542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nmylist = [item[0] for item in training_data[70:100]]\n\n\nimages_per_row = 5\nnum_rows = len(mylist)//images_per_row + (1 if len(mylist)%images_per_row else 0)\n\nplt.figure(figsize=(20, 4*num_rows)) # figsize = (Width, height) in inches\nfor i,img in enumerate(mylist):\n    plt.subplot(num_rows, images_per_row, i+1)\n    plt.imshow(img)\n    plt.title(f'Image {i}')\n    plt.axis('off')\n    \nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:16:19.187630Z","iopub.execute_input":"2024-02-01T14:16:19.188267Z","iopub.status.idle":"2024-02-01T14:16:23.944968Z","shell.execute_reply.started":"2024-02-01T14:16:19.188237Z","shell.execute_reply":"2024-02-01T14:16:23.942087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from tensorflow.keras.callbacks import TensorBoard\n\nimport time\n\nNAME = \"pain-classifier-6Blocks-{}\".format(int( time.time() ))\n\ntensorboard = TensorBoard( log_dir=\"logs/{}\".format(NAME) )\n\nmodel.fit(X, y, epochs=3, validation_split=0.3, batch_size=16, callbacks=[tensorboard]) \n\n%%cmd\ntensorboard --logdir=logs/","metadata":{}},{"cell_type":"code","source":"import pickle\n\npickle_out = open(\"train.pickle\",\"wb\")\npickle.dump(training_data, pickle_out)\npickle_out.close()","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:17:22.581877Z","iopub.execute_input":"2024-02-01T14:17:22.582914Z","iopub.status.idle":"2024-02-01T14:17:38.524496Z","shell.execute_reply.started":"2024-02-01T14:17:22.582878Z","shell.execute_reply":"2024-02-01T14:17:38.523448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN Architecture Code","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Activation, Conv2D, BatchNormalization, Dropout, MaxPooling2D\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow import cast\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport cv2\nimport pickle","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:17:38.526497Z","iopub.execute_input":"2024-02-01T14:17:38.527237Z","iopub.status.idle":"2024-02-01T14:17:38.532835Z","shell.execute_reply.started":"2024-02-01T14:17:38.527198Z","shell.execute_reply":"2024-02-01T14:17:38.531872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pickle_in = open(\"train.pickle\",\"rb\")\ntrain_data = pickle.load(pickle_in)\nlen(training_data)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:17:38.534122Z","iopub.execute_input":"2024-02-01T14:17:38.534499Z","iopub.status.idle":"2024-02-01T14:17:41.143969Z","shell.execute_reply.started":"2024-02-01T14:17:38.534468Z","shell.execute_reply":"2024-02-01T14:17:41.143032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom tensorflow.keras.callbacks import TensorBoard","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:17:41.145633Z","iopub.execute_input":"2024-02-01T14:17:41.145951Z","iopub.status.idle":"2024-02-01T14:17:41.150396Z","shell.execute_reply.started":"2024-02-01T14:17:41.145925Z","shell.execute_reply":"2024-02-01T14:17:41.149426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NAME = \"Pain-classification-COLOR-{}\".format( int(time.time()) )\ntensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:17:47.505486Z","iopub.execute_input":"2024-02-01T14:17:47.505855Z","iopub.status.idle":"2024-02-01T14:17:47.510738Z","shell.execute_reply.started":"2024-02-01T14:17:47.505828Z","shell.execute_reply":"2024-02-01T14:17:47.509803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def normalize_image(image):\n    image = cast(image, tf.float32)\n    image = (image / 127.5) - 1\n    return image","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:17:51.664473Z","iopub.execute_input":"2024-02-01T14:17:51.664978Z","iopub.status.idle":"2024-02-01T14:17:51.670425Z","shell.execute_reply.started":"2024-02-01T14:17:51.664933Z","shell.execute_reply":"2024-02-01T14:17:51.669509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filtered_training_data = [item for item in training_data ]\n\nlabels = [item[1] for item in filtered_training_data]\n\nimages = [np.array(item[0], dtype=np.uint8) for item in filtered_training_data if item is not None]","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:18:08.305929Z","iopub.execute_input":"2024-02-01T14:18:08.306303Z","iopub.status.idle":"2024-02-01T14:18:09.338799Z","shell.execute_reply.started":"2024-02-01T14:18:08.306272Z","shell.execute_reply":"2024-02-01T14:18:09.337953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg_data = [cv2.resize(img, (96, 96), interpolation=cv2.INTER_LINEAR) for img in images]\n\nimages_array = np.array(img_data)\nlabels_array = np.array(labels)\n\nimages_array = normalize_image(images_array)","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:20:12.796762Z","iopub.execute_input":"2024-02-01T14:20:12.797165Z","iopub.status.idle":"2024-02-01T14:20:15.201819Z","shell.execute_reply.started":"2024-02-01T14:20:12.797136Z","shell.execute_reply":"2024-02-01T14:20:15.200793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_array_one_hot = to_categorical(labels_array, num_classes=2)\nlabels_array_one_hot","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:20:19.223422Z","iopub.execute_input":"2024-02-01T14:20:19.223809Z","iopub.status.idle":"2024-02-01T14:20:19.231154Z","shell.execute_reply.started":"2024-02-01T14:20:19.223779Z","shell.execute_reply":"2024-02-01T14:20:19.230337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"no_of_filters = [32,64,96,96]\n\nmodel = Sequential()\n\n#Block 1\nmodel.add( Conv2D( filters = 32, kernel_size=(3,3), input_shape=(96,96,3) ) )\nmodel.add( BatchNormalization() )\nmodel.add( Activation(\"relu\") )\nmodel.add( MaxPooling2D(pool_size=(2,2)) )\nmodel.add( Dropout(0.2) )\n\nfor i in no_of_filters:\n    model.add( Conv2D( filters = i, kernel_size=(3,3) ) )\n    model.add( BatchNormalization() )\n    model.add( Activation(\"relu\") )\n    model.add( MaxPooling2D( pool_size=(2,2) ) )\n    model.add( Dropout(0.2) )\n    \nmodel.add( Conv2D( filters = 64, kernel_size=(3,3), padding='SAME' ) )\nmodel.add( BatchNormalization() )\nmodel.add( Activation(\"relu\") )\nmodel.add( MaxPooling2D( pool_size=(2,2), padding='SAME' ) )\nmodel.add( Dropout(0.2) )\n\n# Flatten\nmodel.add( Flatten() )\n\nmodel.add( Dense(256)   )\nmodel.add( BatchNormalization() )\nmodel.add( Activation(\"relu\") )\nmodel.add( Dropout(0.2) )\nmodel.add( Dense(256) )\n\nmodel.add( BatchNormalization() )\nmodel.add( Activation(\"relu\") )\nmodel.add( Dropout(0.2) )\n#model.add( Dense(7) )\n\n# Output Layer\nmodel.add( Dense(2, activation='softmax') )","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:21:09.451233Z","iopub.execute_input":"2024-02-01T14:21:09.451998Z","iopub.status.idle":"2024-02-01T14:21:09.808028Z","shell.execute_reply.started":"2024-02-01T14:21:09.451967Z","shell.execute_reply":"2024-02-01T14:21:09.807122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\",\n             optimizer=\"adam\",\n             metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:21:10.029114Z","iopub.execute_input":"2024-02-01T14:21:10.029727Z","iopub.status.idle":"2024-02-01T14:21:10.041643Z","shell.execute_reply.started":"2024-02-01T14:21:10.029697Z","shell.execute_reply":"2024-02-01T14:21:10.040766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(images_array, labels_array_one_hot, batch_size=16, epochs=27, validation_split=0.3, callbacks=[tensorboard])","metadata":{"execution":{"iopub.status.busy":"2024-02-01T17:59:47.783478Z","iopub.execute_input":"2024-02-01T17:59:47.784128Z","iopub.status.idle":"2024-02-01T17:59:48.159955Z","shell.execute_reply.started":"2024-02-01T17:59:47.784085Z","shell.execute_reply":"2024-02-01T17:59:48.158455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nimport os\n\nfolder_path = 'logs'  # Folder you want to zip\nzip_path = 'logs.zip'  # Output ZIP file name\n\nwith zipfile.ZipFile(zip_path, 'w') as zipf:\n    for root, dirs, files in os.walk(folder_path):\n        for file in files:\n            file_path = os.path.join(root, file)\n            zipf.write(file_path, os.path.relpath(file_path, os.path.join(folder_path, '..')))\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:42:13.013357Z","iopub.execute_input":"2024-02-01T14:42:13.014119Z","iopub.status.idle":"2024-02-01T14:42:13.023565Z","shell.execute_reply.started":"2024-02-01T14:42:13.014087Z","shell.execute_reply":"2024-02-01T14:42:13.022435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('/kaggle/working/SAS.h5')","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:40:03.882689Z","iopub.execute_input":"2024-02-01T14:40:03.883084Z","iopub.status.idle":"2024-02-01T14:40:04.023866Z","shell.execute_reply.started":"2024-02-01T14:40:03.883053Z","shell.execute_reply":"2024-02-01T14:40:04.022968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('SAS.keras')","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:40:33.286596Z","iopub.execute_input":"2024-02-01T14:40:33.287497Z","iopub.status.idle":"2024-02-01T14:40:33.461686Z","shell.execute_reply.started":"2024-02-01T14:40:33.287462Z","shell.execute_reply":"2024-02-01T14:40:33.460700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%load_ext tensorboard\n%tensorboard --logdir logs/\n","metadata":{"execution":{"iopub.status.busy":"2024-02-01T14:41:45.055074Z","iopub.execute_input":"2024-02-01T14:41:45.056085Z","iopub.status.idle":"2024-02-01T14:41:53.597791Z","shell.execute_reply.started":"2024-02-01T14:41:45.056051Z","shell.execute_reply":"2024-02-01T14:41:53.596833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}